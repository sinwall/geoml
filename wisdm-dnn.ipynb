{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"78ba7276ca7520b75e078490fe8903ecbd27a619a51829001806ed27188ed733"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'DejaVu Sans Mono'","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:17:22.090731Z","iopub.execute_input":"2023-01-04T11:17:22.091414Z","iopub.status.idle":"2023-01-04T11:17:22.097984Z","shell.execute_reply.started":"2023-01-04T11:17:22.091343Z","shell.execute_reply":"2023-01-04T11:17:22.096417Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from scipy.interpolate import interp1d\nfrom sklearn.preprocessing import LabelEncoder\nimport itertools\n\nclass Preprocessor():\n    def __init__(self, gap_max=1.0, seg_dur=5.0, ol_rate=0.5, resamp_gap=0.01):\n        self.gap_max = gap_max\n        self.seg_dur = seg_dur\n        self.ol_rate = ol_rate\n        self.resamp_gap = resamp_gap\n\n    def transform(self, df):\n        gap_max = self.gap_max\n        seg_dur = self.seg_dur\n        ol_rate = self.ol_rate\n        resamp_gap = self.resamp_gap\n\n        users = sorted(df['user'].unique())\n        activities = sorted(df['activity'].unique())\n\n        segments = []\n        seg_usrs = []\n        seg_acts = []\n\n        for user, activity in itertools.product(users, activities):\n            mask_ua = (df['user'] == user) & (df['activity'] == activity)\n            if not mask_ua.any():\n                continue\n            cpnt_nums = np.cumsum( (df.loc[mask_ua, 'timestamp'].diff() > gap_max) | (df.loc[mask_ua, 'timestamp'].diff() < 0) )\n            for num in range(cpnt_nums.min(), cpnt_nums.max()+1):\n                cpnt = df[mask_ua][cpnt_nums == num]\n                cpnt['timestamp'] -= cpnt['timestamp'].min()\n                if cpnt['timestamp'].max() < seg_dur:\n                    continue\n                f = interp1d(cpnt['timestamp'], cpnt[['ax', 'ay', 'az']], axis=0, kind='cubic')\n                for i in np.arange( (cpnt['timestamp'].max()-seg_dur)/(seg_dur*(1-ol_rate)), dtype=np.int32 ):\n                    t = np.arange(0, seg_dur, resamp_gap) + i*seg_dur*(1-ol_rate)\n                    segments.append( f(t) ), seg_usrs.append( user ), seg_acts.append( activity )\n        segments = np.array(segments); seg_usrs = np.array(seg_usrs)\n\n        X = segments\n        label_encoder = LabelEncoder()\n        y = label_encoder.fit_transform(seg_acts)\n\n        self.seg_usrs = seg_usrs\n        self.label_encoder = label_encoder\n        return X, y\n\ndf = pd.read_csv(\n    '../input/wisdm-ar-v11/WISDM_ar_v1.1_raw_modified.txt', \n    names=['user', 'activity', 'timestamp', 'ax', 'ay', 'az'],\n    header=None)\ndf['timestamp'] *= 1e-9\ndf = df[df['timestamp'] != 0]\ndf = df[~df['timestamp'].duplicated()]\ndf = df.dropna()\ndf = df.reset_index(drop=True)\n\nusers = sorted(df['user'].unique())\nactivities = sorted(df['activity'].unique())","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:17:22.100880Z","iopub.execute_input":"2023-01-04T11:17:22.101510Z","iopub.status.idle":"2023-01-04T11:17:23.233450Z","shell.execute_reply.started":"2023-01-04T11:17:22.101457Z","shell.execute_reply":"2023-01-04T11:17:23.232028Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from tools import Embedder, SineFilter\n\nkey = (5, 4, 0, 5, 'identity')\nseg_dur, lag, reduce, dim_raw, method = key\npreprocessor = Preprocessor(seg_dur=seg_dur)\nX, y = preprocessor.transform(df)\nembedder = Embedder(lag=lag, reduce=reduce, dim_raw=dim_raw, channel_last=True)\npts = embedder.transform(X)\n# weights = np.load(f'./output/w_WISDM/{key}_20221110.npy')\n# # weights = np.ones(pts.shape[:-1] + (1, ))\n# sine_filter = SineFilter(dim=pts.shape[-1], n_filters=16, random_state=42)\n# scale = np.average(np.linalg.norm(pts, axis=-1, keepdims=True), axis=-2, weights=weights/np.sum(weights, axis=-2, keepdims=True))[...,np.newaxis]\n# fs = sine_filter.apply(pts/scale, weights)\nfs = np.empty_like(pts)[..., :1]","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:17:23.235024Z","iopub.execute_input":"2023-01-04T11:17:23.235451Z","iopub.status.idle":"2023-01-04T11:17:43.637468Z","shell.execute_reply.started":"2023-01-04T11:17:23.235406Z","shell.execute_reply":"2023-01-04T11:17:43.636358Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport random\n\nclass MyModel(keras.Model):\n    def __init__(self, n_classes, use_weights=False):\n        super(MyModel, self).__init__()\n        self.n_classes = n_classes\n\n        self.main_layers = [\n            keras.layers.GRU(\n                units=256,\n                return_sequences=True\n            ), \n            keras.layers.Conv1D(\n                filters=128,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.Conv1D(\n                filters=64,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.AveragePooling1D(\n                pool_size=2\n            ),\n            keras.layers.Conv1D(\n                filters=32,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.AveragePooling1D(\n                pool_size=2\n            ),\n            keras.layers.Conv1D(\n                filters=16,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.AveragePooling1D(\n                pool_size=2\n            ),\n\n            keras.layers.Flatten(),\n            keras.layers.BatchNormalization(),\n            keras.layers.Dense(\n                units=16,\n                activation='elu'\n            ),\n            keras.layers.BatchNormalization()\n        ]\n        self.aux_layers = [\n            keras.layers.Flatten(),\n            keras.layers.Dense(\n                units=16,\n                activation='elu'\n            )\n        ]\n        self.final_layers = [\n            keras.layers.Dense(\n                units=n_classes,\n                activation='softmax'\n            )\n        ]\n        self.use_weights = use_weights\n    \n    def call(self, inputs, training=None):\n        outputs, weights = inputs\n        for layer in self.main_layers:\n            outputs = layer(outputs, training=training)\n        for layer in self.aux_layers:\n            weights = layer(weights, training=training)\n        if self.use_weights:\n            outputs = tf.concat([outputs, weights], axis=-1)\n        for layer in self.final_layers:\n            outputs = layer(outputs, training=training)\n        return outputs\n\nrng = np.random.default_rng(42)\nusrs_test = rng.choice(users, 12, replace=False)\nusrs_val = usrs_test[:6]\nusrs_test = usrs_test[6:]\nmask_test = np.isin(preprocessor.seg_usrs, usrs_test)\nmask_val = np.isin(preprocessor.seg_usrs, usrs_val)\nmask_train = ~(mask_val | mask_test)\n\ncallbacks = [\n    keras.callbacks.EarlyStopping(\n        patience=20, \n        min_delta=1e-4,\n        restore_best_weights=True\n    )\n]\n\nkeras.backend.clear_session()\nfor use_weights in (False, ):\n    tf.random.set_seed(42); random.seed(42); np.random.seed(42)\n\n    model = MyModel(n_classes=6, use_weights=use_weights)\n    model.compile(\n        loss='sparse_categorical_crossentropy',\n        optimizer=keras.optimizers.Adam(1e-3),\n        metrics=['accuracy']\n    )\n    model.fit(\n        (X[mask_train], fs[mask_train]), \n        y[mask_train],\n        epochs=50,\n        batch_size=1<<10,\n        callbacks=callbacks,\n        validation_data=((X[mask_val], fs[mask_val]), y[mask_val]),\n    )\n    model.evaluate((X[mask_test], fs[mask_test]), y[mask_test])","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:17:43.639910Z","iopub.execute_input":"2023-01-04T11:17:43.640621Z","iopub.status.idle":"2023-01-04T15:38:29.692638Z","shell.execute_reply.started":"2023-01-04T11:17:43.640583Z","shell.execute_reply":"2023-01-04T15:38:29.691401Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/50\n14/14 [==============================] - 309s 22s/step - loss: 1.3487 - accuracy: 0.5534 - val_loss: 3.3817 - val_accuracy: 0.5024\nEpoch 2/50\n14/14 [==============================] - 307s 22s/step - loss: 0.8894 - accuracy: 0.7523 - val_loss: 4.5641 - val_accuracy: 0.5174\nEpoch 3/50\n14/14 [==============================] - 313s 22s/step - loss: 0.7474 - accuracy: 0.7791 - val_loss: 4.0785 - val_accuracy: 0.5894\nEpoch 4/50\n14/14 [==============================] - 304s 22s/step - loss: 0.6117 - accuracy: 0.8177 - val_loss: 1.9853 - val_accuracy: 0.6778\nEpoch 5/50\n14/14 [==============================] - 304s 22s/step - loss: 0.5261 - accuracy: 0.8475 - val_loss: 1.4532 - val_accuracy: 0.7016\nEpoch 6/50\n14/14 [==============================] - 306s 22s/step - loss: 0.4445 - accuracy: 0.8751 - val_loss: 1.1428 - val_accuracy: 0.7204\nEpoch 7/50\n14/14 [==============================] - 313s 22s/step - loss: 0.3817 - accuracy: 0.8953 - val_loss: 1.3753 - val_accuracy: 0.7343\nEpoch 8/50\n14/14 [==============================] - 312s 22s/step - loss: 0.3209 - accuracy: 0.9103 - val_loss: 1.4225 - val_accuracy: 0.7338\nEpoch 9/50\n14/14 [==============================] - 311s 22s/step - loss: 0.2620 - accuracy: 0.9293 - val_loss: 1.6162 - val_accuracy: 0.7319\nEpoch 10/50\n14/14 [==============================] - 308s 22s/step - loss: 0.2326 - accuracy: 0.9369 - val_loss: 1.4806 - val_accuracy: 0.7541\nEpoch 11/50\n14/14 [==============================] - 307s 22s/step - loss: 0.1871 - accuracy: 0.9531 - val_loss: 1.8103 - val_accuracy: 0.7290\nEpoch 12/50\n14/14 [==============================] - 306s 22s/step - loss: 0.1588 - accuracy: 0.9618 - val_loss: 1.5731 - val_accuracy: 0.7328\nEpoch 13/50\n14/14 [==============================] - 318s 23s/step - loss: 0.1467 - accuracy: 0.9649 - val_loss: 1.0323 - val_accuracy: 0.7784\nEpoch 14/50\n14/14 [==============================] - 309s 22s/step - loss: 0.1294 - accuracy: 0.9687 - val_loss: 1.0900 - val_accuracy: 0.7724\nEpoch 15/50\n14/14 [==============================] - 312s 22s/step - loss: 0.1076 - accuracy: 0.9755 - val_loss: 1.5535 - val_accuracy: 0.7374\nEpoch 16/50\n14/14 [==============================] - 316s 23s/step - loss: 0.0897 - accuracy: 0.9798 - val_loss: 1.6117 - val_accuracy: 0.7395\nEpoch 17/50\n14/14 [==============================] - 315s 23s/step - loss: 0.0801 - accuracy: 0.9819 - val_loss: 0.9188 - val_accuracy: 0.7993\nEpoch 18/50\n14/14 [==============================] - 314s 22s/step - loss: 0.0710 - accuracy: 0.9849 - val_loss: 1.0454 - val_accuracy: 0.7896\nEpoch 19/50\n14/14 [==============================] - 317s 23s/step - loss: 0.0691 - accuracy: 0.9848 - val_loss: 0.8790 - val_accuracy: 0.7915\nEpoch 20/50\n14/14 [==============================] - 315s 23s/step - loss: 0.0573 - accuracy: 0.9891 - val_loss: 0.7812 - val_accuracy: 0.8127\nEpoch 21/50\n14/14 [==============================] - 318s 23s/step - loss: 0.0561 - accuracy: 0.9893 - val_loss: 0.7072 - val_accuracy: 0.8422\nEpoch 22/50\n14/14 [==============================] - 317s 23s/step - loss: 0.0491 - accuracy: 0.9912 - val_loss: 0.5263 - val_accuracy: 0.8730\nEpoch 23/50\n14/14 [==============================] - 310s 22s/step - loss: 0.0431 - accuracy: 0.9939 - val_loss: 0.6256 - val_accuracy: 0.8286\nEpoch 24/50\n14/14 [==============================] - 312s 22s/step - loss: 0.0383 - accuracy: 0.9943 - val_loss: 0.6086 - val_accuracy: 0.8522\nEpoch 25/50\n14/14 [==============================] - 307s 22s/step - loss: 0.0391 - accuracy: 0.9936 - val_loss: 0.5142 - val_accuracy: 0.8687\nEpoch 26/50\n14/14 [==============================] - 310s 22s/step - loss: 0.0343 - accuracy: 0.9948 - val_loss: 0.4311 - val_accuracy: 0.9063\nEpoch 27/50\n14/14 [==============================] - 311s 22s/step - loss: 0.0308 - accuracy: 0.9957 - val_loss: 0.4872 - val_accuracy: 0.8811\nEpoch 28/50\n14/14 [==============================] - 312s 22s/step - loss: 0.0311 - accuracy: 0.9949 - val_loss: 0.4458 - val_accuracy: 0.8947\nEpoch 29/50\n14/14 [==============================] - 314s 23s/step - loss: 0.0428 - accuracy: 0.9887 - val_loss: 0.5556 - val_accuracy: 0.8823\nEpoch 30/50\n14/14 [==============================] - 315s 23s/step - loss: 0.0391 - accuracy: 0.9910 - val_loss: 0.3770 - val_accuracy: 0.9004\nEpoch 31/50\n14/14 [==============================] - 310s 22s/step - loss: 0.0294 - accuracy: 0.9962 - val_loss: 0.3687 - val_accuracy: 0.8949\nEpoch 32/50\n14/14 [==============================] - 308s 22s/step - loss: 0.0242 - accuracy: 0.9968 - val_loss: 0.4863 - val_accuracy: 0.8887\nEpoch 33/50\n14/14 [==============================] - 311s 22s/step - loss: 0.0193 - accuracy: 0.9982 - val_loss: 0.4596 - val_accuracy: 0.8751\nEpoch 34/50\n14/14 [==============================] - 313s 22s/step - loss: 0.0173 - accuracy: 0.9981 - val_loss: 0.4761 - val_accuracy: 0.8875\nEpoch 35/50\n14/14 [==============================] - 315s 23s/step - loss: 0.0157 - accuracy: 0.9985 - val_loss: 0.4876 - val_accuracy: 0.8935\nEpoch 36/50\n14/14 [==============================] - 322s 23s/step - loss: 0.0137 - accuracy: 0.9987 - val_loss: 0.4991 - val_accuracy: 0.8816\nEpoch 37/50\n14/14 [==============================] - 325s 23s/step - loss: 0.0123 - accuracy: 0.9988 - val_loss: 0.4818 - val_accuracy: 0.8904\nEpoch 38/50\n14/14 [==============================] - 318s 23s/step - loss: 0.0120 - accuracy: 0.9991 - val_loss: 0.4975 - val_accuracy: 0.8897\nEpoch 39/50\n14/14 [==============================] - 315s 23s/step - loss: 0.0193 - accuracy: 0.9965 - val_loss: 0.8210 - val_accuracy: 0.8210\nEpoch 40/50\n14/14 [==============================] - 310s 22s/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 0.6236 - val_accuracy: 0.8480\nEpoch 41/50\n14/14 [==============================] - 311s 22s/step - loss: 0.0156 - accuracy: 0.9980 - val_loss: 0.4996 - val_accuracy: 0.9009\nEpoch 42/50\n14/14 [==============================] - 307s 22s/step - loss: 0.0121 - accuracy: 0.9986 - val_loss: 0.4874 - val_accuracy: 0.8913\nEpoch 43/50\n14/14 [==============================] - 311s 22s/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.4605 - val_accuracy: 0.8918\nEpoch 44/50\n14/14 [==============================] - 311s 22s/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 0.4910 - val_accuracy: 0.8982\nEpoch 45/50\n14/14 [==============================] - 312s 22s/step - loss: 0.0095 - accuracy: 0.9991 - val_loss: 0.4203 - val_accuracy: 0.9049\nEpoch 46/50\n14/14 [==============================] - 316s 23s/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.4916 - val_accuracy: 0.8961\nEpoch 47/50\n14/14 [==============================] - 312s 22s/step - loss: 0.0075 - accuracy: 0.9996 - val_loss: 0.4541 - val_accuracy: 0.9016\nEpoch 48/50\n14/14 [==============================] - 312s 22s/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 0.4540 - val_accuracy: 0.9016\nEpoch 49/50\n14/14 [==============================] - 313s 22s/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.4640 - val_accuracy: 0.9040\nEpoch 50/50\n14/14 [==============================] - 311s 22s/step - loss: 0.0061 - accuracy: 0.9997 - val_loss: 0.4713 - val_accuracy: 0.9023\n105/105 [==============================] - 38s 360ms/step - loss: 0.4490 - accuracy: 0.9202\n","output_type":"stream"}]}]}