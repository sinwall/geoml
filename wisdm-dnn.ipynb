{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"78ba7276ca7520b75e078490fe8903ecbd27a619a51829001806ed27188ed733"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'DejaVu Sans Mono'","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:09:34.337765Z","iopub.execute_input":"2023-01-05T09:09:34.338449Z","iopub.status.idle":"2023-01-05T09:09:34.369697Z","shell.execute_reply.started":"2023-01-05T09:09:34.338344Z","shell.execute_reply":"2023-01-05T09:09:34.368749Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from scipy.interpolate import interp1d\nfrom sklearn.preprocessing import LabelEncoder\nimport itertools\n\nclass Preprocessor():\n    def __init__(self, gap_max=1.0, seg_dur=5.0, ol_rate=0.5, resamp_gap=0.01):\n        self.gap_max = gap_max\n        self.seg_dur = seg_dur\n        self.ol_rate = ol_rate\n        self.resamp_gap = resamp_gap\n\n    def transform(self, df):\n        gap_max = self.gap_max\n        seg_dur = self.seg_dur\n        ol_rate = self.ol_rate\n        resamp_gap = self.resamp_gap\n\n        users = sorted(df['user'].unique())\n        activities = sorted(df['activity'].unique())\n\n        segments = []\n        seg_usrs = []\n        seg_acts = []\n\n        for user, activity in itertools.product(users, activities):\n            mask_ua = (df['user'] == user) & (df['activity'] == activity)\n            if not mask_ua.any():\n                continue\n            cpnt_nums = np.cumsum( (df.loc[mask_ua, 'timestamp'].diff() > gap_max) | (df.loc[mask_ua, 'timestamp'].diff() < 0) )\n            for num in range(cpnt_nums.min(), cpnt_nums.max()+1):\n                cpnt = df[mask_ua][cpnt_nums == num]\n                cpnt['timestamp'] -= cpnt['timestamp'].min()\n                if cpnt['timestamp'].max() < seg_dur:\n                    continue\n                f = interp1d(cpnt['timestamp'], cpnt[['ax', 'ay', 'az']], axis=0, kind='cubic')\n                for i in np.arange( (cpnt['timestamp'].max()-seg_dur)/(seg_dur*(1-ol_rate)), dtype=np.int32 ):\n                    t = np.arange(0, seg_dur, resamp_gap) + i*seg_dur*(1-ol_rate)\n                    segments.append( f(t) ), seg_usrs.append( user ), seg_acts.append( activity )\n        segments = np.array(segments); seg_usrs = np.array(seg_usrs)\n\n        X = segments\n        label_encoder = LabelEncoder()\n        y = label_encoder.fit_transform(seg_acts)\n\n        self.seg_usrs = seg_usrs\n        self.label_encoder = label_encoder\n        return X, y\n\ndf = pd.read_csv(\n    '../input/wisdm-ar-v11/WISDM_ar_v1.1_raw_modified.txt', \n    names=['user', 'activity', 'timestamp', 'ax', 'ay', 'az'],\n    header=None)\ndf['timestamp'] *= 1e-9\ndf = df[df['timestamp'] != 0]\ndf = df[~df['timestamp'].duplicated()]\ndf = df.dropna()\ndf = df.reset_index(drop=True)\n\nusers = sorted(df['user'].unique())\nactivities = sorted(df['activity'].unique())","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:09:34.371999Z","iopub.execute_input":"2023-01-05T09:09:34.372465Z","iopub.status.idle":"2023-01-05T09:09:37.525954Z","shell.execute_reply.started":"2023-01-05T09:09:34.372426Z","shell.execute_reply":"2023-01-05T09:09:37.524736Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tools import Embedder, SineFilter\n\nkey = (5, 4, 0, 5, 'identity')\nseg_dur, lag, reduce, dim_raw, method = key\npreprocessor = Preprocessor(seg_dur=seg_dur)\nX, y = preprocessor.transform(df)\nembedder = Embedder(lag=lag, reduce=reduce, dim_raw=dim_raw, channel_last=True)\npts = embedder.transform(X)\n# weights = np.load(f'./output/w_WISDM/{key}_20221110.npy')\n# # weights = np.ones(pts.shape[:-1] + (1, ))\n# sine_filter = SineFilter(dim=pts.shape[-1], n_filters=16, random_state=42)\n# scale = np.average(np.linalg.norm(pts, axis=-1, keepdims=True), axis=-2, weights=weights/np.sum(weights, axis=-2, keepdims=True))[...,np.newaxis]\n# fs = sine_filter.apply(pts/scale, weights)\nfs = np.empty_like(pts)[..., :1]","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:09:37.531896Z","iopub.execute_input":"2023-01-05T09:09:37.534569Z","iopub.status.idle":"2023-01-05T09:09:57.474561Z","shell.execute_reply.started":"2023-01-05T09:09:37.534522Z","shell.execute_reply":"2023-01-05T09:09:57.473451Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport random\n\nclass MyModel(keras.Model):\n    def __init__(self, n_classes, use_weights=False):\n        super(MyModel, self).__init__()\n        self.n_classes = n_classes\n\n        self.main_layers = [\n            keras.layers.Conv1D(\n                filters=1024,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.Conv1D(\n                filters=512,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.Conv1D(\n                filters=256,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.Conv1D(\n                filters=128,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.Conv1D(\n                filters=64,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.AveragePooling1D(\n                pool_size=2\n            ),\n            keras.layers.Conv1D(\n                filters=32,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.AveragePooling1D(\n                pool_size=2\n            ),\n            keras.layers.Conv1D(\n                filters=16,\n                kernel_size=8,\n                activation='elu'\n            ),\n            keras.layers.AveragePooling1D(\n                pool_size=2\n            ),\n\n            keras.layers.Flatten(),\n            keras.layers.BatchNormalization(),\n            keras.layers.Dense(\n                units=16,\n                activation='elu'\n            ),\n            keras.layers.BatchNormalization()\n        ]\n        self.aux_layers = [\n            keras.layers.Flatten(),\n            keras.layers.Dense(\n                units=16,\n                activation='elu'\n            )\n        ]\n        self.final_layers = [\n            keras.layers.Dense(\n                units=n_classes,\n                activation='softmax'\n            )\n        ]\n        self.use_weights = use_weights\n    \n    def call(self, inputs, training=None):\n        outputs, weights = inputs\n        for layer in self.main_layers:\n            outputs = layer(outputs, training=training)\n        for layer in self.aux_layers:\n            weights = layer(weights, training=training)\n        if self.use_weights:\n            outputs = tf.concat([outputs, weights], axis=-1)\n        for layer in self.final_layers:\n            outputs = layer(outputs, training=training)\n        return outputs\n\nrng = np.random.default_rng(42)\nusrs_test = rng.choice(users, 12, replace=False)\nusrs_val = usrs_test[:6]\nusrs_test = usrs_test[6:]\nmask_test = np.isin(preprocessor.seg_usrs, usrs_test)\nmask_val = np.isin(preprocessor.seg_usrs, usrs_val)\nmask_train = ~(mask_val | mask_test)\n\ncallbacks = [\n    keras.callbacks.EarlyStopping(\n        patience=20, \n        min_delta=1e-4,\n        restore_best_weights=True\n    )\n]\n\nwith tf.device('gpu:0'):\n    keras.backend.clear_session()\n    for use_weights in (False, ):\n        tf.random.set_seed(42); random.seed(42); np.random.seed(42)\n\n        model = MyModel(n_classes=6, use_weights=use_weights)\n        model.compile(\n            loss='sparse_categorical_crossentropy',\n            optimizer=keras.optimizers.Adam(1e-3),\n            metrics=['accuracy']\n        )\n        model.fit(\n            (X[mask_train], fs[mask_train]), \n            y[mask_train],\n            epochs=50,\n            batch_size=1<<10,\n            callbacks=callbacks,\n            validation_data=((X[mask_val], fs[mask_val]), y[mask_val]),\n        )\n        model.evaluate((X[mask_test], fs[mask_test]), y[mask_test])","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:46:04.543196Z","iopub.execute_input":"2023-01-05T09:46:04.543582Z","iopub.status.idle":"2023-01-05T10:20:33.859208Z","shell.execute_reply.started":"2023-01-05T09:46:04.543540Z","shell.execute_reply":"2023-01-05T10:20:33.858187Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2023-01-05 09:46:41.663627: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.96GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n2023-01-05 09:46:41.664900: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.96GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","output_type":"stream"},{"name":"stdout","text":"14/14 [==============================] - 111s 5s/step - loss: 1.3311 - accuracy: 0.5649 - val_loss: 14.8322 - val_accuracy: 0.4285\nEpoch 2/50\n14/14 [==============================] - 46s 3s/step - loss: 0.8301 - accuracy: 0.7541 - val_loss: 7.4059 - val_accuracy: 0.5968\nEpoch 3/50\n14/14 [==============================] - 47s 3s/step - loss: 0.7040 - accuracy: 0.7749 - val_loss: 5.6249 - val_accuracy: 0.6223\nEpoch 4/50\n14/14 [==============================] - 46s 3s/step - loss: 0.5665 - accuracy: 0.8164 - val_loss: 3.4619 - val_accuracy: 0.6745\nEpoch 5/50\n14/14 [==============================] - 47s 3s/step - loss: 0.4864 - accuracy: 0.8508 - val_loss: 2.4506 - val_accuracy: 0.7135\nEpoch 6/50\n14/14 [==============================] - 46s 3s/step - loss: 0.4192 - accuracy: 0.8815 - val_loss: 1.5345 - val_accuracy: 0.7390\nEpoch 7/50\n14/14 [==============================] - 46s 3s/step - loss: 0.3502 - accuracy: 0.9034 - val_loss: 0.8941 - val_accuracy: 0.7855\nEpoch 8/50\n14/14 [==============================] - 47s 3s/step - loss: 0.2884 - accuracy: 0.9198 - val_loss: 1.3742 - val_accuracy: 0.7014\nEpoch 9/50\n14/14 [==============================] - 47s 3s/step - loss: 0.2570 - accuracy: 0.9282 - val_loss: 0.8982 - val_accuracy: 0.7479\nEpoch 10/50\n14/14 [==============================] - 47s 3s/step - loss: 0.2330 - accuracy: 0.9368 - val_loss: 0.9164 - val_accuracy: 0.7738\nEpoch 11/50\n14/14 [==============================] - 46s 3s/step - loss: 0.1877 - accuracy: 0.9490 - val_loss: 0.6882 - val_accuracy: 0.7793\nEpoch 12/50\n14/14 [==============================] - 47s 3s/step - loss: 0.1833 - accuracy: 0.9510 - val_loss: 1.0168 - val_accuracy: 0.6966\nEpoch 13/50\n14/14 [==============================] - 46s 3s/step - loss: 0.1507 - accuracy: 0.9614 - val_loss: 0.7372 - val_accuracy: 0.7724\nEpoch 14/50\n14/14 [==============================] - 47s 3s/step - loss: 0.1152 - accuracy: 0.9739 - val_loss: 1.4416 - val_accuracy: 0.4676\nEpoch 15/50\n14/14 [==============================] - 47s 3s/step - loss: 0.1028 - accuracy: 0.9768 - val_loss: 1.5844 - val_accuracy: 0.4240\nEpoch 16/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0862 - accuracy: 0.9805 - val_loss: 2.2712 - val_accuracy: 0.2402\nEpoch 17/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0747 - accuracy: 0.9846 - val_loss: 2.7752 - val_accuracy: 0.2648\nEpoch 18/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0669 - accuracy: 0.9868 - val_loss: 2.4924 - val_accuracy: 0.2216\nEpoch 19/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0614 - accuracy: 0.9876 - val_loss: 2.2274 - val_accuracy: 0.3179\nEpoch 20/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0646 - accuracy: 0.9858 - val_loss: 2.4630 - val_accuracy: 0.2488\nEpoch 21/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0714 - accuracy: 0.9829 - val_loss: 1.5487 - val_accuracy: 0.5286\nEpoch 22/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0659 - accuracy: 0.9861 - val_loss: 2.0651 - val_accuracy: 0.4445\nEpoch 23/50\n14/14 [==============================] - 47s 3s/step - loss: 0.1078 - accuracy: 0.9705 - val_loss: 0.4145 - val_accuracy: 0.8742\nEpoch 24/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0797 - accuracy: 0.9786 - val_loss: 0.8140 - val_accuracy: 0.8325\nEpoch 25/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0619 - accuracy: 0.9855 - val_loss: 0.4380 - val_accuracy: 0.8534\nEpoch 26/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0426 - accuracy: 0.9923 - val_loss: 0.7780 - val_accuracy: 0.6792\nEpoch 27/50\n14/14 [==============================] - 46s 3s/step - loss: 0.0358 - accuracy: 0.9944 - val_loss: 0.5081 - val_accuracy: 0.8315\nEpoch 28/50\n14/14 [==============================] - 46s 3s/step - loss: 0.0349 - accuracy: 0.9938 - val_loss: 0.7083 - val_accuracy: 0.7538\nEpoch 29/50\n14/14 [==============================] - 46s 3s/step - loss: 0.0296 - accuracy: 0.9948 - val_loss: 0.7663 - val_accuracy: 0.7235\nEpoch 30/50\n14/14 [==============================] - 46s 3s/step - loss: 0.0234 - accuracy: 0.9970 - val_loss: 1.1711 - val_accuracy: 0.5667\nEpoch 31/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0198 - accuracy: 0.9979 - val_loss: 1.6483 - val_accuracy: 0.4204\nEpoch 32/50\n14/14 [==============================] - 46s 3s/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 1.1643 - val_accuracy: 0.6053\nEpoch 33/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0196 - accuracy: 0.9973 - val_loss: 1.1942 - val_accuracy: 0.5567\nEpoch 34/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0180 - accuracy: 0.9979 - val_loss: 0.6694 - val_accuracy: 0.7595\nEpoch 35/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0154 - accuracy: 0.9983 - val_loss: 1.5664 - val_accuracy: 0.4716\nEpoch 36/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 1.2636 - val_accuracy: 0.5503\nEpoch 37/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0130 - accuracy: 0.9981 - val_loss: 0.9514 - val_accuracy: 0.6418\nEpoch 38/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0117 - accuracy: 0.9986 - val_loss: 1.0191 - val_accuracy: 0.6330\nEpoch 39/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0150 - accuracy: 0.9978 - val_loss: 0.7947 - val_accuracy: 0.7019\nEpoch 40/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0141 - accuracy: 0.9978 - val_loss: 0.8267 - val_accuracy: 0.7271\nEpoch 41/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0125 - accuracy: 0.9985 - val_loss: 0.5661 - val_accuracy: 0.8060\nEpoch 42/50\n14/14 [==============================] - 47s 3s/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.7830 - val_accuracy: 0.7383\nEpoch 43/50\n14/14 [==============================] - 46s 3s/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 0.5792 - val_accuracy: 0.7939\n105/105 [==============================] - 4s 35ms/step - loss: 0.3997 - accuracy: 0.9246\n","output_type":"stream"}]}]}