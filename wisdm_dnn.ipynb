{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans Mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import itertools\n",
    "\n",
    "class Preprocessor():\n",
    "    def __init__(self, gap_max=1.0, seg_dur=5.0, ol_rate=0.5, resamp_gap=0.01):\n",
    "        self.gap_max = gap_max\n",
    "        self.seg_dur = seg_dur\n",
    "        self.ol_rate = ol_rate\n",
    "        self.resamp_gap = resamp_gap\n",
    "\n",
    "    def transform(self, df):\n",
    "        gap_max = self.gap_max\n",
    "        seg_dur = self.seg_dur\n",
    "        ol_rate = self.ol_rate\n",
    "        resamp_gap = self.resamp_gap\n",
    "\n",
    "        users = sorted(df['user'].unique())\n",
    "        activities = sorted(df['activity'].unique())\n",
    "\n",
    "        segments = []\n",
    "        seg_usrs = []\n",
    "        seg_acts = []\n",
    "\n",
    "        for user, activity in itertools.product(users, activities):\n",
    "            mask_ua = (df['user'] == user) & (df['activity'] == activity)\n",
    "            if not mask_ua.any():\n",
    "                continue\n",
    "            cpnt_nums = np.cumsum( (df.loc[mask_ua, 'timestamp'].diff() > gap_max) | (df.loc[mask_ua, 'timestamp'].diff() < 0) )\n",
    "            for num in range(cpnt_nums.min(), cpnt_nums.max()+1):\n",
    "                cpnt = df[mask_ua][cpnt_nums == num]\n",
    "                cpnt['timestamp'] -= cpnt['timestamp'].min()\n",
    "                if cpnt['timestamp'].max() < seg_dur:\n",
    "                    continue\n",
    "                f = interp1d(cpnt['timestamp'], cpnt[['ax', 'ay', 'az']], axis=0, kind='cubic')\n",
    "                for i in np.arange( (cpnt['timestamp'].max()-seg_dur)/(seg_dur*(1-ol_rate)), dtype=np.int32 ):\n",
    "                    t = np.arange(0, seg_dur, resamp_gap) + i*seg_dur*(1-ol_rate)\n",
    "                    segments.append( f(t) ), seg_usrs.append( user ), seg_acts.append( activity )\n",
    "        segments = np.array(segments); seg_usrs = np.array(seg_usrs)\n",
    "\n",
    "        X = segments\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(seg_acts)\n",
    "\n",
    "        self.seg_usrs = seg_usrs\n",
    "        self.label_encoder = label_encoder\n",
    "        return X, y\n",
    "\n",
    "df = pd.read_csv(\n",
    "    '../input/WISDM_ar_v1.1/WISDM_ar_v1.1_raw_modified.txt', \n",
    "    names=['user', 'activity', 'timestamp', 'ax', 'ay', 'az'],\n",
    "    header=None)\n",
    "df['timestamp'] *= 1e-9\n",
    "df = df[df['timestamp'] != 0]\n",
    "df = df[~df['timestamp'].duplicated()]\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "users = sorted(df['user'].unique())\n",
    "activities = sorted(df['activity'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import Embedder, SineFilter\n",
    "\n",
    "key = (5, 4, 0, 5, 'identity')\n",
    "seg_dur, lag, reduce, dim_raw, method = key\n",
    "preprocessor = Preprocessor(seg_dur=seg_dur)\n",
    "X, y = preprocessor.transform(df)\n",
    "embedder = Embedder(lag=lag, reduce=reduce, dim_raw=dim_raw, channel_last=True)\n",
    "pts = embedder.transform(X)\n",
    "# weights = np.load(f'./output/w_WISDM/{key}_20221110.npy')\n",
    "# # weights = np.ones(pts.shape[:-1] + (1, ))\n",
    "# sine_filter = SineFilter(dim=pts.shape[-1], n_filters=16, random_state=42)\n",
    "# scale = np.average(np.linalg.norm(pts, axis=-1, keepdims=True), axis=-2, weights=weights/np.sum(weights, axis=-2, keepdims=True))[...,np.newaxis]\n",
    "# fs = sine_filter.apply(pts/scale, weights)\n",
    "fs = np.empty_like(pts)[..., :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, n_classes, use_weights=False):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.main_layers = [\n",
    "            # keras.layers.GRU(\n",
    "            #     units=512,\n",
    "            #     # dropout=0.3,\n",
    "            #     # recurrent_dropout=0.3,\n",
    "            #     return_sequences=True\n",
    "            # ),\n",
    "            keras.layers.GRU(\n",
    "                units=256,\n",
    "                # dropout=0.3,\n",
    "                # recurrent_dropout=0.3,\n",
    "                return_sequences=True\n",
    "            ), \n",
    "            keras.layers.GRU(\n",
    "                units=128,\n",
    "                # dropout=0.3,\n",
    "                # recurrent_dropout=0.3,\n",
    "                return_sequences=True\n",
    "            ),\n",
    "\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32,\n",
    "                kernel_size=16,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.AveragePooling1D(\n",
    "                pool_size=2\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32,\n",
    "                kernel_size=16,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.AveragePooling1D(\n",
    "                pool_size=2\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32,\n",
    "                kernel_size=16,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.AveragePooling1D(\n",
    "                pool_size=2\n",
    "            ),\n",
    "            # keras.layers.Conv1D(\n",
    "            #     filters=32,\n",
    "            #     kernel_size=16,\n",
    "            #     activation='elu'\n",
    "            # ),\n",
    "            # keras.layers.AveragePooling1D(\n",
    "            #     pool_size=2\n",
    "            # ),\n",
    "            # keras.layers.Conv1D(\n",
    "            #     filters=32,\n",
    "            #     kernel_size=16,\n",
    "            #     activation='elu'\n",
    "            # ),\n",
    "            # keras.layers.AveragePooling1D(\n",
    "            #     pool_size=2\n",
    "            # ),\n",
    "\n",
    "            keras.layers.Flatten(),\n",
    "            # keras.layers.Dense(\n",
    "            #     units=32,\n",
    "            #     activation='elu'\n",
    "            # ),\n",
    "            keras.layers.Dense(\n",
    "                units=16,\n",
    "                activation='elu'\n",
    "            ),\n",
    "        ]\n",
    "        self.aux_layers = [\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(\n",
    "                units=16,\n",
    "                activation='elu'\n",
    "            )\n",
    "        ]\n",
    "        self.final_layers = [\n",
    "            keras.layers.Dense(\n",
    "                units=n_classes,\n",
    "                activation='softmax'\n",
    "            )\n",
    "        ]\n",
    "        self.use_weights = use_weights\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        outputs, weights = inputs\n",
    "        for layer in self.main_layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        for layer in self.aux_layers:\n",
    "            weights = layer(weights, training=training)\n",
    "        if self.use_weights:\n",
    "            outputs = tf.concat([outputs, weights], axis=-1)\n",
    "        for layer in self.final_layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        return outputs\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "usrs_test = rng.choice(users, 12, replace=False)\n",
    "usrs_val = usrs_test[:6]\n",
    "usrs_test = usrs_test[6:]\n",
    "mask_test = np.isin(preprocessor.seg_usrs, usrs_test)\n",
    "mask_val = np.isin(preprocessor.seg_usrs, usrs_val)\n",
    "mask_train = ~(mask_val | mask_test)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        patience=20, \n",
    "        min_delta=1e-4,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "for use_weights in (False, True):\n",
    "    tf.random.set_seed(42); random.seed(42); np.random.seed(42)\n",
    "\n",
    "    model = MyModel(n_classes=6, use_weights=use_weights)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        (X[mask_train], fs[mask_train]), \n",
    "        y[mask_train],\n",
    "        epochs=50,\n",
    "        batch_size=1<<10,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=((X[mask_val], fs[mask_val]), y[mask_val]),\n",
    "    )\n",
    "    model.evaluate((X[mask_test], fs[mask_test]), y[mask_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78ba7276ca7520b75e078490fe8903ecbd27a619a51829001806ed27188ed733"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
