{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans Mono'\n",
    "import ubisum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import itertools\n",
    "\n",
    "class Preprocessor():\n",
    "    def __init__(self, gap_max=1.0, seg_dur=5.0, ol_rate=0.5, resamp_gap=0.01):\n",
    "        self.gap_max = gap_max\n",
    "        self.seg_dur = seg_dur\n",
    "        self.ol_rate = ol_rate\n",
    "        self.resamp_gap = resamp_gap\n",
    "\n",
    "    def transform(self, df):\n",
    "        gap_max = self.gap_max\n",
    "        seg_dur = self.seg_dur\n",
    "        ol_rate = self.ol_rate\n",
    "        resamp_gap = self.resamp_gap\n",
    "\n",
    "        users = sorted(df['user'].unique())\n",
    "        activities = sorted(df['activity'].unique())\n",
    "\n",
    "        segments = []\n",
    "        seg_usrs = []\n",
    "        seg_acts = []\n",
    "\n",
    "        for user, activity in itertools.product(users, activities):\n",
    "            mask_ua = (df['user'] == user) & (df['activity'] == activity)\n",
    "            if not mask_ua.any():\n",
    "                continue\n",
    "            cpnt_nums = np.cumsum( (df.loc[mask_ua, 'timestamp'].diff() > gap_max) | (df.loc[mask_ua, 'timestamp'].diff() < 0) )\n",
    "            for num in range(cpnt_nums.min(), cpnt_nums.max()+1):\n",
    "                cpnt = df[mask_ua][cpnt_nums == num]\n",
    "                cpnt['timestamp'] -= cpnt['timestamp'].min()\n",
    "                if cpnt['timestamp'].max() < seg_dur:\n",
    "                    continue\n",
    "                f = interp1d(cpnt['timestamp'], cpnt[['ax', 'ay', 'az']], axis=0, kind='cubic')\n",
    "                for i in np.arange( (cpnt['timestamp'].max()-seg_dur)/(seg_dur*(1-ol_rate)), dtype=np.int32 ):\n",
    "                    t = np.arange(0, seg_dur, resamp_gap) + i*seg_dur*(1-ol_rate)\n",
    "                    segments.append( f(t) ), seg_usrs.append( user ), seg_acts.append( activity )\n",
    "        segments = np.array(segments); seg_usrs = np.array(seg_usrs)\n",
    "\n",
    "        X = segments\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(seg_acts)\n",
    "\n",
    "        self.seg_usrs = seg_usrs\n",
    "        self.label_encoder = label_encoder\n",
    "        return X, y\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f'{ubisum.input_path}/WISDM_ar_v1.1/WISDM_ar_v1.1_raw_modified.txt', \n",
    "    names=['user', 'activity', 'timestamp', 'ax', 'ay', 'az'],\n",
    "    header=None)\n",
    "df['timestamp'] *= 1e-9\n",
    "df = df[df['timestamp'] != 0]\n",
    "df = df[~df['timestamp'].duplicated()]\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "users = sorted(df['user'].unique())\n",
    "activities = sorted(df['activity'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import Embedder, SineFilter\n",
    "\n",
    "key = (5, 4, 0, 5, 'identity')\n",
    "seg_dur, lag, reduce, dim_raw, method = key\n",
    "preprocessor = Preprocessor(seg_dur=seg_dur)\n",
    "X, y = preprocessor.transform(df)\n",
    "embedder = Embedder(lag=lag, reduce=reduce, dim_raw=dim_raw, channel_last=True)\n",
    "pts = embedder.transform(X)\n",
    "weights = np.load(f'./output/w_WISDM/{key}_20221110.npy')\n",
    "# weights = np.ones(pts.shape[:-1] + (1, ))\n",
    "sine_filter = SineFilter(dim=pts.shape[-1], n_filters=16, random_state=42)\n",
    "scale = np.average(np.linalg.norm(pts, axis=-1, keepdims=True), axis=-2, weights=weights/np.sum(weights, axis=-2, keepdims=True))[...,np.newaxis]\n",
    "fs = sine_filter.apply(pts/scale, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['my_model/dense_2/kernel:0', 'my_model/dense_2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['my_model/dense_2/kernel:0', 'my_model/dense_2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "14/14 [==============================] - 12174s 870s/step - loss: 1.1922 - accuracy: 0.5958 - val_loss: 1.6550 - val_accuracy: 0.2376\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 12076s 865s/step - loss: 0.7006 - accuracy: 0.8136 - val_loss: 1.4203 - val_accuracy: 0.4566\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 12067s 864s/step - loss: 0.5528 - accuracy: 0.8563 - val_loss: 1.0259 - val_accuracy: 0.6785\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 12085s 866s/step - loss: 0.4473 - accuracy: 0.8815 - val_loss: 0.9516 - val_accuracy: 0.7233\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 12071s 864s/step - loss: 0.3680 - accuracy: 0.9026 - val_loss: 1.0191 - val_accuracy: 0.7002\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 12071s 865s/step - loss: 0.3113 - accuracy: 0.9182 - val_loss: 0.8252 - val_accuracy: 0.7624\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 12067s 864s/step - loss: 0.2592 - accuracy: 0.9368 - val_loss: 0.8572 - val_accuracy: 0.7333\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 12070s 865s/step - loss: 0.2158 - accuracy: 0.9477 - val_loss: 0.8409 - val_accuracy: 0.7550\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 12070s 865s/step - loss: 0.1897 - accuracy: 0.9555 - val_loss: 0.8379 - val_accuracy: 0.7500\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 12078s 865s/step - loss: 0.1667 - accuracy: 0.9604 - val_loss: 0.9201 - val_accuracy: 0.7057\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 12062s 864s/step - loss: 0.1530 - accuracy: 0.9638 - val_loss: 0.9337 - val_accuracy: 0.7128\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 12077s 865s/step - loss: 0.1386 - accuracy: 0.9681 - val_loss: 0.9766 - val_accuracy: 0.6864\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 12069s 865s/step - loss: 0.1188 - accuracy: 0.9739 - val_loss: 1.0092 - val_accuracy: 0.6752\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 12082s 865s/step - loss: 0.1115 - accuracy: 0.9752 - val_loss: 1.1021 - val_accuracy: 0.6428\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 12075s 865s/step - loss: 0.1048 - accuracy: 0.9751 - val_loss: 1.3340 - val_accuracy: 0.5901\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 12079s 865s/step - loss: 0.0887 - accuracy: 0.9816 - val_loss: 0.9156 - val_accuracy: 0.7164\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 12078s 865s/step - loss: 0.0839 - accuracy: 0.9823 - val_loss: 0.7996 - val_accuracy: 0.7238\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 12065s 864s/step - loss: 0.0785 - accuracy: 0.9843 - val_loss: 0.5740 - val_accuracy: 0.7757\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 12061s 864s/step - loss: 0.0810 - accuracy: 0.9826 - val_loss: 0.5040 - val_accuracy: 0.8041\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 12063s 864s/step - loss: 0.0728 - accuracy: 0.9828 - val_loss: 0.5850 - val_accuracy: 0.7962\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 13554s 979s/step - loss: 0.0598 - accuracy: 0.9884 - val_loss: 0.5570 - val_accuracy: 0.8270\n",
      "Epoch 22/50\n",
      " 5/14 [=========>....................] - ETA: 2:22:10 - loss: 0.0586 - accuracy: 0.9891"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, n_classes, use_weights=False):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.main_layers = [\n",
    "            keras.layers.GRU(\n",
    "                units=64,\n",
    "                # dropout=0.3,\n",
    "                # recurrent_dropout=0.3,\n",
    "                return_sequences=True\n",
    "            ),\n",
    "            keras.layers.GRU(\n",
    "                units=64,\n",
    "                # dropout=0.3,\n",
    "                # recurrent_dropout=0.3,\n",
    "                return_sequences=True\n",
    "            ), \n",
    "            keras.layers.GRU(\n",
    "                units=64,\n",
    "                # dropout=0.3,\n",
    "                # recurrent_dropout=0.3,\n",
    "                return_sequences=True\n",
    "            ),\n",
    "\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32,\n",
    "                kernel_size=8,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.AveragePooling1D(\n",
    "                pool_size=2\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32,\n",
    "                kernel_size=8,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.AveragePooling1D(\n",
    "                pool_size=2\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32,\n",
    "                kernel_size=8,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.AveragePooling1D(\n",
    "                pool_size=2\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32,\n",
    "                kernel_size=8,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.AveragePooling1D(\n",
    "                pool_size=2\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32,\n",
    "                kernel_size=8,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.AveragePooling1D(\n",
    "                pool_size=2\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(\n",
    "                units=32,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(\n",
    "                units=16,\n",
    "                activation='elu'\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "        ]\n",
    "        self.aux_layers = [\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(\n",
    "                units=16,\n",
    "                activation='elu'\n",
    "            )\n",
    "        ]\n",
    "        self.final_layers = [\n",
    "            keras.layers.Dense(\n",
    "                units=n_classes,\n",
    "                activation='softmax'\n",
    "            )\n",
    "        ]\n",
    "        self.use_weights = use_weights\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        outputs, weights = inputs\n",
    "        for layer in self.main_layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        for layer in self.aux_layers:\n",
    "            weights = layer(weights, training=training)\n",
    "        if self.use_weights:\n",
    "            outputs = tf.concat([outputs, weights], axis=-1)\n",
    "        for layer in self.final_layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        return outputs\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "usrs_test = rng.choice(users, 12, replace=False)\n",
    "usrs_val = usrs_test[:6]\n",
    "usrs_test = usrs_test[6:]\n",
    "mask_test = np.isin(preprocessor.seg_usrs, usrs_test)\n",
    "mask_val = np.isin(preprocessor.seg_usrs, usrs_val)\n",
    "mask_train = ~(mask_val | mask_test)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        patience=20, \n",
    "        min_delta=1e-4,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "for use_weights in (False, True):\n",
    "    tf.random.set_seed(42); random.seed(42); np.random.seed(42)\n",
    "\n",
    "    model = MyModel(n_classes=6, use_weights=use_weights)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        (X[mask_train], fs[mask_train]), \n",
    "        y[mask_train],\n",
    "        epochs=50,\n",
    "        batch_size=1<<10,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=((X[mask_val], fs[mask_val]), y[mask_val]),\n",
    "    )\n",
    "    model.evaluate((X[mask_test], fs[mask_test]), y[mask_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78ba7276ca7520b75e078490fe8903ecbd27a619a51829001806ed27188ed733"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
